{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRCNN_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artiumb/IRIS_SR_CNN/blob/master/SRCNN_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSoeCL3Mq8vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some references:\n",
        "# https://github.com/Mirwaisse/SRCNN \n",
        "# https://github.com/basher666/pytorch_srcnn\n",
        "# https://github.com/MarkPrecursor/SRCNN-keras <-based on this\n",
        "# https://github.com/thuyngch/Iris-Recognition-PyTorch\n",
        "# http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html : original paper site\n",
        "#paper:\n",
        "# http://personal.ie.cuhk.edu.hk/~ccloy/files/eccv_2014_deepresolution.pdf\n",
        "#updated paper 2015:\n",
        "# https://arxiv.org/pdf/1501.00092.pdf\n",
        "#resnet for SR:\n",
        "# https://github.com/yulunzhang/RDN#results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzD1988B5VgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "drive.mount(\"/content/drive/\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Out2CihnQMUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -av '/content/drive/My Drive/Toar2/Thesis/Iris_recog/CASIA Iris Image Database (version 1.0)/.' '/content/Dataset_casia_V1_HR'\n",
        "!cp -av '/content/drive/My Drive/Toar2/Thesis/Iris_recog/CASIA Iris Image Database (version 1.0)/jpeg/.' '/content/Dataset_casia_V1_HR'\n",
        "# !rm -rf '/content/Dataset_casia_V1_LR'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChxAklkSXrzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy to local env\n",
        "# !cp -avr '/content/drive/My Drive/Toar2/Thesis/Iris_recog/srcnn_keras_dataset/' '/content/'\n",
        "# !mkdir 'Dataset'\n",
        "\n",
        "# !rm -rf 'Dataset'\n",
        "if (False):\n",
        "    !cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/IrisResizedOriginal/Dataset/Original-240x320/Casia-v4-240x320/.' '/content/Dataset_casia_h'\n",
        "    print('casia done')\n",
        "    !cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/IrisResizedOriginal/Dataset/Original-240x320/berc-240x320/.' '/content/Dataset_berc_h'\n",
        "    print('berc done')\n",
        "    !cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/IrisResizedOriginal/Dataset/Original-240x320/ndcld-240x320/.' '/content/Dataset_ndcld_h'\n",
        "    # Drive/Toar2/Thesis/Iris_recog/IrisResizedOriginal.zip (Unzipped Files)/IrisResizedOriginal/Dataset/Original-240x320/ndcld-240x320\n",
        "    print('ndcld done')\n",
        "    !cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/IrisResizedOriginal/Dataset/Resize-60x80/Casia-v4-60x80/.' '/content/Dataset_casia_l'\n",
        "    print('casia done')\n",
        "    !cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/IrisResizedOriginal/Dataset/Resize-60x80/berc-60x80/.' '/content/Dataset_berc_l'\n",
        "    print('berc done')\n",
        "    !cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/IrisResizedOriginal/Dataset/Resize-60x80/ndcld-60x80/.' '/content/Dataset_ndcld_l'\n",
        "    print('ndcld done')\n",
        "#  Tload validation\n",
        "    \n",
        "    print('validation done')\n",
        " # unite datasets:\n",
        "    !cp -ar '/content/Dataset_casia_h/.' '/content/CombinedDataset_h'\n",
        "    !cp -ar '/content/Dataset_berc_h/.' '/content/CombinedDataset_h'\n",
        "    !cp -ar '/content/Dataset_ndcld_h/.' '/content/CombinedDataset_h'\n",
        "     # unite datasets:\n",
        "    !cp -ar '/content/Dataset_casia_l/.' '/content/CombinedDataset_l'\n",
        "    !cp -ar '/content/Dataset_berc_l/.' '/content/CombinedDataset_l'\n",
        "    !cp -ar '/content/Dataset_ndcld_l/.' '/content/CombinedDataset_l'\n",
        "    print('combine done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLuVBpTCUS_7",
        "colab_type": "code",
        "outputId": "43714f1d-46d9-45e0-d884-925a00110d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# split dataset directory to train and test subdirs (random)\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "def img_train_test_split_per_person(img_source_dir_l,img_source_dir_h, train_size,dataset_name,rndseed):\n",
        "\n",
        "    # Randomly splits images over a train and validation folder (both LR and HR)\n",
        "\n",
        "    # High res   \n",
        "    if not (isinstance(img_source_dir_h, str)):\n",
        "        raise AttributeError('img_source_dir must be a string')\n",
        "    if not os.path.exists(img_source_dir_h):\n",
        "        raise OSError('img_source_dir does not exist')    \n",
        "    if not (isinstance(train_size, float)):\n",
        "        raise AttributeError('train_size must be a float')        \n",
        "    if not os.path.exists(img_source_dir_h + '/data'):\n",
        "        os.makedirs(img_source_dir_h + '/data')\n",
        "    else:\n",
        "        if not os.path.exists(img_source_dir_h + '/data/train'):\n",
        "            os.makedirs(img_source_dir_h + '/data/train')\n",
        "        if not os.path.exists(img_source_dir_h + '/data/validation'):\n",
        "            os.makedirs(img_source_dir_h + '/data/validation')\n",
        "            \n",
        "        train_subdir_h = img_source_dir_h + '/data/train'\n",
        "        validation_subdir_h = img_source_dir_h + '/data/validation'\n",
        "#low res\n",
        "    if not (isinstance(img_source_dir_l, str)):\n",
        "        raise AttributeError('img_source_dir must be a string')\n",
        "    if not os.path.exists(img_source_dir_l):\n",
        "        raise OSError('img_source_dir does not exist')    \n",
        "    if not (isinstance(train_size, float)):\n",
        "        raise AttributeError('train_size must be a float')        \n",
        "    if not os.path.exists(img_source_dir_l + '/data'):\n",
        "        os.makedirs(img_source_dir_l + '/data')\n",
        "    else:\n",
        "        if not os.path.exists(img_source_dir_l + '/data/train'):\n",
        "            os.makedirs(img_source_dir_l + '/data/train')\n",
        "        if not os.path.exists(img_source_dir_l + '/data/validation'):\n",
        "            os.makedirs(img_source_dir_l + '/data/validation')\n",
        "        \n",
        "        \n",
        "        train_subdir_l = img_source_dir_l + '/data/train'\n",
        "        validation_subdir_l = img_source_dir_l + '/data/validation'\n",
        "\n",
        "        # Create subdirectories in train and validation folders\n",
        "        if not os.path.exists(train_subdir_h):\n",
        "            os.makedirs(train_subdir_h)\n",
        "        if not os.path.exists(validation_subdir_h):\n",
        "            os.makedirs(validation_subdir_h)\n",
        "        if not os.path.exists(train_subdir_l):\n",
        "            os.makedirs(train_subdir_l)\n",
        "        if not os.path.exists(validation_subdir_l):\n",
        "            os.makedirs(validation_subdir_l)\n",
        "\n",
        "        train_counter = 0\n",
        "        validation_counter = 0\n",
        "        train_name_counter = 0\n",
        "        validation_name_counter = 0\n",
        "        subdir_fullpath = img_source_dir_h\n",
        "        name_list_train = []\n",
        "        name_list_val = []\n",
        "        print(dataset_name)\n",
        "        random.seed(rndseed)\n",
        "        # Randomly assign an image to train or validation folder\n",
        "        for filename in os.listdir(subdir_fullpath):\n",
        "            if filename.endswith(\".jpg\"): \n",
        "                #each dataset marks person if in different way\n",
        "                if (dataset_name == \"casia_V1\"):\n",
        "                    fileparts = filename.split('_')\n",
        "                    person_id =  fileparts[0]\n",
        "                else:\n",
        "                    fileparts = filename.split('-')\n",
        "                    if (dataset_name == \"casia\"):\n",
        "                        person_id = re.split ('L|R',str(fileparts[3]))[0]\n",
        "                    if (dataset_name == \"berc\"):\n",
        "                        person_id = re.split ('_l_',str(fileparts[1] +  fileparts[2]))[0]\n",
        "                    if (dataset_name == \"ndcld\"):\n",
        "                        person_id = re.split( 'd', str(fileparts[2]).strip('.jpg'))[0]\n",
        "                # parse ids\n",
        "                print(person_id)\n",
        "                if random.uniform(0, 1) <= train_size:\n",
        "                    if person_id not in name_list_train:\n",
        "                        if person_id not in name_list_val:\n",
        "                            name_list_train.append(person_id)\n",
        "                            train_name_counter += 1\n",
        "                else:\n",
        "                    if person_id not in name_list_train:\n",
        "                        if person_id not in name_list_val:\n",
        "                            name_list_val.append(person_id)\n",
        "                            validation_name_counter += 1 \n",
        "        print('done names' )\n",
        "        print(' Total: val names' + str(validation_name_counter) + ' train names' +str(train_name_counter) )  \n",
        "         \n",
        "        for filename in os.listdir(subdir_fullpath):\n",
        "            if filename.endswith(\".jpg\"): \n",
        "                #each dataset marks person if in different way\n",
        "                if (dataset_name == \"casia_V1\"):\n",
        "                    fileparts = filename.split('_')\n",
        "                    person_id =  fileparts[0]\n",
        "                else:\n",
        "                    fileparts = filename.split('-')\n",
        "                    if (dataset_name == \"casia\"):\n",
        "                        person_id = re.split ('L|R',str(fileparts[3]))[0]\n",
        "                    if (dataset_name == \"berc\"):\n",
        "                        person_id = re.split ('_l_',str(fileparts[1] +  fileparts[2]))[0]\n",
        "                    if (dataset_name == \"ndcld\"):\n",
        "                        person_id = re.split( 'd', str(fileparts[2]).strip('.jpg'))[0]\n",
        "\n",
        "                if person_id in name_list_train:\n",
        "                    copyfile(os.path.join(img_source_dir_h, filename), os.path.join(train_subdir_h, filename))\n",
        "                    copyfile(os.path.join(img_source_dir_l, filename), os.path.join(train_subdir_l, filename))\n",
        "                    train_counter += 1\n",
        "                if person_id  in name_list_val:\n",
        "                    copyfile(os.path.join(img_source_dir_h, filename), os.path.join(validation_subdir_h,filename))\n",
        "                    copyfile(os.path.join(img_source_dir_l, filename), os.path.join(validation_subdir_l,filename))\n",
        "                    validation_counter += 1     \n",
        "                      \n",
        "              \n",
        "        print('Copied ' + str(train_counter) + ' images to data/train/' )\n",
        "        print('Copied ' + str(validation_counter) + ' images to data/validation/' )\n",
        "        \n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmRKLvS-fLUa",
        "colab_type": "code",
        "outputId": "67a51b2c-acc6-45b9-ff04-50203a422561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def img_create_LR_Dataset(source_dir_HR,source_dir_LR,scale):\n",
        "    if not os.path.exists(source_dir_LR):\n",
        "        os.makedirs(source_dir_LR)\n",
        "    counter = 0;\n",
        "    names = [f for f in os.listdir(source_dir_HR) if f.endswith(\".jpg\")]\n",
        "    names = sorted(names)\n",
        "    nums = names.__len__()\n",
        "\n",
        "    for i in range(nums):\n",
        "        name = source_dir_HR + names[i]\n",
        "        # print('name ' + name)\n",
        "\n",
        "        hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
        "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
        "        hr_img = hr_img[:, :, 0]\n",
        "        shape = hr_img.shape\n",
        "\n",
        "        lr_img = cv2.resize(hr_img, (int(shape[1] / scale),int( shape[0]/scale)), cv2.INTER_CUBIC)\n",
        "        lr_img_path = source_dir_LR + names[i]\n",
        "        cv2.imwrite(lr_img_path, lr_img)\n",
        "        counter = counter+1;\n",
        "    print('Downscaled and copied: ' + str(counter) + ' to ' + str(source_dir_LR) )\n",
        "print('done')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA0zRCQJWJpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int(322/ scale)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DRks958qymf",
        "colab_type": "code",
        "outputId": "e2b69dfc-75d3-4918-ead6-4acac96350f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import os\n",
        "if (True):\n",
        "    # create LR images for many scale factors\n",
        "    # scales = [1.5,2.0,3.0,4.0,5.0,6.0, 8.0,9.0,10.0,11.0,12.0,14.0,16.0]\n",
        "    scales = [ 5.0 ]\n",
        "    for scale in scales:\n",
        "        lr_path_for_scale = '/content/Dataset_casia_V1_LR_'+ str(scale) +'/'\n",
        "        print('scale =' ,scale,' ' ,lr_path_for_scale )\n",
        "        img_create_LR_Dataset('/content/Dataset_casia_V1_HR/',lr_path_for_scale, scale)\n",
        "        print('done')\n",
        "\n",
        "\n",
        "# Backup  casia Dataset V1 HR and LR To drive\n",
        "# ..."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scale = 5.0   /content/Dataset_casia_V1_LR_5.0/\n",
            "Downscaled and copied: 766 to /content/Dataset_casia_V1_LR_5.0/\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNfyzCQaAn2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "if (False):\n",
        "    img_train_test_split_per_person('/content/Dataset_berc_l/','/content/Dataset_berc_h/',0.7,\"berc\")\n",
        "    img_train_test_split_per_person('/content/Dataset_casia_l/','/content/Dataset_casia_h/',0.7,\"casia\")\n",
        "    img_train_test_split_per_person('/content/Dataset_ndcld_l/','/content/Dataset_ndcld_h/',0.7,\"ndcld\")\n",
        "\n",
        "if (False):\n",
        "# casia V1\n",
        "scales = [1.5,2.0,3.0,4.0,5.0,6.0, 8.0,9.0,10.0,11.0,12.0,14.0,16.0]\n",
        "for scale in scales:\n",
        "    lr_path_for_scale = '/content/Dataset_casia_V1_LR_'+ str(scale) +'/'\n",
        "    print('scale =' ,scale,' ' ,lr_path_for_scale )\n",
        "    img_train_test_split_per_person(lr_path_for_scale , '/content/Dataset_casia_V1_HR/' ,0.7,'casia_V1',25)\n",
        "    print('done')\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMiXQ6VeX6Qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf '/content/Dataset_berc_l/data'\n",
        "!rm -rf '/content/Dataset_berc_h/data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU8XS-N1-mjH",
        "colab_type": "code",
        "outputId": "5082a379-5f4f-4975-cdf3-440d99a966d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#create test and validation\n",
        "from shutil import copytree\n",
        "import os\n",
        "if (False):\n",
        "    # img_train_test_split('/content/Dataset_berc/',0.7)\n",
        "    # img_train_test_split('/content/Dataset_casia/',0.7)\n",
        "    # img_train_test_split('/content/Dataset_ndcld/',0.7)\n",
        "#     img_train_test_split('/content/CombinedDataset/',0.7)\n",
        "\n",
        "#     if not os.path.exists('/content/drive/My Drive/Toar2/Thesis/Iris_recog/Dataset_ndcld_split'):\n",
        "#     os.makedirs('/content/drive/My Drive/Toar2/Thesis/Iris_recog/Dataset_ndcld_split')\n",
        "     \n",
        "#save backup to drive:\n",
        "    # casia V1 LR\n",
        "    copytree('/content/Dataset_casia_V1_HR/data', os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' 'Dataset_casia_V1_split_h_multi'))\n",
        "    print('done')\n",
        "    scales = [1.5,2.0,3.0,4.0,5.0,6.0,8.0,9.0,10.0,11.0,12.0,14.0,16.0]\n",
        "    for scale in scales:\n",
        "        lr_path_scaled = '/content/Dataset_casia_V1_LR_'+ str(scale) +'/' + 'data'\n",
        "        lr_path_scaled_drive = 'Dataset_casia_V1_split_l_multi_'+ str(scale) \n",
        "        print('scale =' ,scale,' ' ,lr_path_scaled , ' ' ,lr_path_scaled_drive )\n",
        "        copytree(lr_path_scaled , os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' ,lr_path_scaled_drive))\n",
        "        print('done')\n",
        "\n",
        "    scales = [ 5.0 ]\n",
        "    for scale in scales:\n",
        "        lr_path_scaled = '/content/Dataset_casia_V1_LR_'+ str(scale)\n",
        "        lr_path_scaled_drive = 'Dataset_casia_V1_split_LR_multi_'+ str(scale) \n",
        "        print('scale =' ,scale,' ' ,lr_path_scaled , ' ' ,lr_path_scaled_drive )\n",
        "        copytree(lr_path_scaled , os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' ,lr_path_scaled_drive))\n",
        "        print('done')\n",
        "\n",
        "    from google.colab import files\n",
        "    scales = [1.5,2.0,3.0,4.0,5.0,6.0, 8.0,9.0,10.0,11.0,12.0,14.0,16.0]\n",
        "    for scale in scales:\n",
        "        lr_path_scaled = '/content/Dataset_casia_V1_LR_'+ str(scale)\n",
        "        files.download(str(lr_path_scaled))\n",
        "\n",
        "     # other datasets split:\n",
        "    copytree('/content/Dataset_ndcld_h/data', os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' 'Dataset_ndcld_split_h'))\n",
        "    copytree('/content/Dataset_casia_h/data', os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' 'Dataset_casia_split_h'))\n",
        "    copytree('/content/Dataset_berc_h/data', os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' 'Dataset_berc_split_h'))\n",
        "    copytree('/content/CombinedDataset_h/data', os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' 'CombinedDataset_split_h'))\n",
        "\n",
        "    copytree('/content/Dataset_ndcld_l/data', os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' 'Dataset_ndcld_split_l'))\n",
        "    copytree('/content/Dataset_casia_l/data', os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' 'Dataset_casia_split_l'))\n",
        "    copytree('/content/Dataset_berc_l/data', os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' 'Dataset_berc_split_l'))\n",
        "    copytree('/content/CombinedDataset_l/data', os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' 'CombinedDataset_split_l'))\n",
        "    print('done')\n",
        "# !rm -rf 'data'\n",
        "# !rm -rf '/content/Dataset_berc/data'\n",
        "# !rm -rf '/content/drive/My Drive/Toar2/Thesis/Dataset_ndcld_split'\n",
        "#count files:\n",
        "    # !ls CombinedDataset | wc -l\n",
        "    \n",
        "    # # unite datasets:\n",
        "# !cp -avr '/content/Dataset_casia/.' '/content/CombinedDataset'\n",
        "# !cp -avr '/content/Dataset_berc/.' '/content/CombinedDataset'\n",
        "# !cp -avr '/content/Dataset_ndcld/.' '/content/CombinedDataset'\n",
        "# print('combine done')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scale = 5.0   /content/Dataset_casia_V1_LR_5.0   Dataset_casia_V1_split_LR_multi_5.0\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iXc2GiSyAYWY",
        "colab": {}
      },
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import cv2\n",
        "import h5py\n",
        "import numpy\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "Patch_size = 32\n",
        "label_size = 20\n",
        "conv_side = 6\n",
        "scale = 4\n",
        "\n",
        "# BORDER_CUT = 8\n",
        "# BLOCK_STEP = 16\n",
        "# BLOCK_SIZE = 32\n",
        "BLOCK_STEP = 8\n",
        "BLOCK_SIZE = 16\n",
        "\n",
        "#prepare_crop_data used for training data\n",
        "def prepare_crop_data(_path_hr):\n",
        "#     print('_path_hr' ,_path_hr)\n",
        "    names = [f for f in os.listdir(_path_hr) if f.endswith(\".jpg\")]\n",
        "    names = sorted(names)\n",
        "    nums = names.__len__()\n",
        "\n",
        "    data = []\n",
        "    label = []\n",
        "\n",
        "    for i in range(nums):\n",
        "        name = _path_hr + names[i]\n",
        "#         print('name' ,name)\n",
        "        hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
        "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
        "        hr_img = hr_img[:, :, 0]\n",
        "        shape = hr_img.shape\n",
        "\n",
        "        # two resize operation to produce training data and labels\n",
        "        lr_img = cv2.resize(hr_img, (int(shape[1] / scale),int( shape[0]/scale)))\n",
        "        lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
        "\n",
        "        width_num = (shape[0] - (BLOCK_SIZE - BLOCK_STEP) * 2) // BLOCK_STEP\n",
        "        height_num = (shape[1] - (BLOCK_SIZE - BLOCK_STEP) * 2) // BLOCK_STEP\n",
        "        for k in range(width_num):\n",
        "            for j in range(height_num):\n",
        "                x = k * BLOCK_STEP\n",
        "                y = j * BLOCK_STEP\n",
        "                hr_patch = hr_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
        "                lr_patch = lr_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
        "#                 print('patch coord ', x, x + BLOCK_SIZE,y, y + BLOCK_SIZE)\n",
        "                lr_patch = lr_patch.astype(float) / 255.\n",
        "                hr_patch = hr_patch.astype(float) / 255.\n",
        "\n",
        "                lr = numpy.zeros((1, Patch_size, Patch_size), dtype=numpy.double)\n",
        "                hr = numpy.zeros((1, label_size, label_size), dtype=numpy.double)\n",
        "\n",
        "                lr[0, :, :] = lr_patch\n",
        "                hr[0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
        "\n",
        "                data.append(lr)\n",
        "                label.append(hr)\n",
        "\n",
        "    data = numpy.array(data, dtype=float)\n",
        "    label = numpy.array(label, dtype=float)\n",
        "    return data, label\n",
        "\n",
        "print('done')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ble_Iy0nhChJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import cv2\n",
        "import h5py\n",
        "import numpy\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "Patch_size = 32\n",
        "label_size = 20\n",
        "conv_side = 6\n",
        "\n",
        "# BORDER_CUT = 8\n",
        "# BLOCK_STEP = 16\n",
        "# BLOCK_SIZE = 32\n",
        "\n",
        "BLOCK_STEP = 16\n",
        "BLOCK_SIZE = Patch_size # 16\n",
        "\n",
        "#prepare_crop_data used for training data\n",
        "def prepare_crop_data_new(_path_L, _path_H):\n",
        "    names = [f for f in os.listdir(_path_H) if f.endswith(\".jpg\")]\n",
        "    names = sorted(names)\n",
        "    nums = names.__len__()\n",
        "\n",
        "    data = []\n",
        "    label = []\n",
        "\n",
        "    for i in range(nums):\n",
        "        name = _path_H + names[i]\n",
        "        name_L = _path_L + names[i]\n",
        "\n",
        "        # print('name' ,name)\n",
        "        hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
        "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
        "        hr_img = hr_img[:, :, 0]\n",
        "        shape_H = hr_img.shape\n",
        "\n",
        "        lr_img = cv2.imread(name_L, cv2.IMREAD_COLOR)\n",
        "        lr_img = cv2.cvtColor(lr_img, cv2.COLOR_BGR2YCrCb)\n",
        "        lr_img = lr_img[:, :, 0]\n",
        "        lr_img = cv2.resize(lr_img, (int(shape_H[1] ),int( shape_H[0])))\n",
        "\n",
        "\n",
        "        width_num = (shape_H[0] - (BLOCK_SIZE - BLOCK_STEP) * 2) // BLOCK_STEP\n",
        "        height_num = (shape_H[1] - (BLOCK_SIZE - BLOCK_STEP) * 2) // BLOCK_STEP\n",
        "        for k in range(width_num):\n",
        "            for j in range(height_num):\n",
        "                x = k * BLOCK_STEP\n",
        "                y = j * BLOCK_STEP\n",
        "                hr_patch = hr_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
        "                lr_patch = lr_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
        "#                 print('patch coord ', x, x + BLOCK_SIZE,y, y + BLOCK_SIZE)\n",
        "                lr_patch = lr_patch.astype(float) / 255.\n",
        "                hr_patch = hr_patch.astype(float) / 255.\n",
        "\n",
        "                lr = numpy.zeros((1, Patch_size, Patch_size), dtype=numpy.double)\n",
        "                hr = numpy.zeros((1, label_size, label_size), dtype=numpy.double)\n",
        "\n",
        "                lr[0, :, :] = lr_patch\n",
        "                hr[0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
        "\n",
        "                data.append(lr)\n",
        "                label.append(hr)\n",
        "\n",
        "    data = numpy.array(data, dtype=float)\n",
        "    label = numpy.array(label, dtype=float)\n",
        "    return data, label\n",
        "\n",
        "print('done')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEwRnTMnxgCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_hdf5(data, labels, output_filename):\n",
        "    \"\"\"\n",
        "    This function is used to save image data and its label(s) to hdf5 file.\n",
        "    output_file.h5,contain data and label\n",
        "    \"\"\"\n",
        "    \n",
        "    x = data.astype(numpy.float32)\n",
        "    y = labels.astype(numpy.float32)\n",
        "\n",
        "    with h5py.File(output_filename, 'w') as h:\n",
        "        h.create_dataset('data', data=x, shape=x.shape)\n",
        "        h.create_dataset('label', data=y, shape=y.shape)\n",
        "        # h.create_dataset()\n",
        "\n",
        "def read_training_data(file):\n",
        "    with h5py.File(file, 'r') as hf:\n",
        "        data = numpy.array(hf.get('data'))\n",
        "        label = numpy.array(hf.get('label'))\n",
        "        train_data = numpy.transpose(data, (0, 2, 3, 1))\n",
        "        train_label = numpy.transpose(label, (0, 2, 3, 1))\n",
        "        return train_data, train_label\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnrgfqejsRnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test\n",
        "if (False):\n",
        "    DATA_PATH = \"Dataset/\"\n",
        "    names = [f for f in os.listdir(DATA_PATH) if f.endswith(\".jpg\")]\n",
        "    names = sorted(names)\n",
        "    nums = names.__len__()\n",
        "\n",
        "    name = DATA_PATH + names[-1]\n",
        "    hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
        "    hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
        "    hr_img = hr_img[:, :, 0]\n",
        "    shape = hr_img.shape\n",
        "\n",
        "    print(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnXCYZZjq-l9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, Dropout\n",
        "# from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import SGD, Adam\n",
        "# import prepare_data as pd\n",
        "import numpy\n",
        "import math\n",
        "\n",
        "def model():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(32, 32, 1)))\n",
        "    SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=3, nb_col=3, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    SRCNN.add(BatchNormalization())\n",
        "\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    SRCNN.add(BatchNormalization())\n",
        "    adam = Adam(lr=0.0003)\n",
        "    # l_rate =1e-5\n",
        "    # opt = SGD(lr=l_rate,momentum = 0.9,decay=(l_rate/100))\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KRlHAfP6OvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def predict_model():\n",
        "    # lrelu = LeakyReLU(alpha=0.1)\n",
        "    SRCNN = Sequential()\n",
        "    SRCNN.add(Conv2D(nb_filter=128, nb_row=9, nb_col=9, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='valid', bias=True, input_shape=(None, None, 1)))\n",
        "    SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=64, nb_row=3, nb_col=3, init='glorot_uniform',\n",
        "                     activation='relu', border_mode='same', bias=True))\n",
        "    SRCNN.add(BatchNormalization())\n",
        "    SRCNN.add(Conv2D(nb_filter=1, nb_row=5, nb_col=5, init='glorot_uniform',\n",
        "                     activation='linear', border_mode='valid', bias=True))\n",
        "    SRCNN.add(BatchNormalization())\n",
        "    adam = Adam(lr=0.0003)\n",
        "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return SRCNN\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udqH4RMO6OFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train(_dataset_path_l,_dataset_path_h,_checkp_name,_numEpochs,load_h5_data,_train_h5_file,_val_h5_file):\n",
        "    srcnn_model = model()\n",
        "    print(srcnn_model.summary())\n",
        "    if (load_h5_data == True):\n",
        "        data, label = read_training_data(_train_h5_file)\n",
        "        val_data, val_label = read_training_data(_val_h5_file)\n",
        "        print(\"loaded h5 dataset: \" + _train_h5_file)\n",
        "        train_data_t = data\n",
        "        train_label_t = label\n",
        "        val_data_t = val_data\n",
        "        val_label_t = val_label\n",
        "    else:\n",
        "        _train_path_l = _dataset_path_l +\"data/train/\"\n",
        "        _train_path_h = _dataset_path_h +\"data/train/\"\n",
        "        _validation_path_l = _dataset_path_l +\"data/validation/\"\n",
        "        _validation_path_h  = _dataset_path_l +\"data/validation/\"\n",
        "        print(\"using directory dataset\" + _dataset_path)\n",
        "\n",
        "        data, label = prepare_crop_data_new(_train_path_l,_train_path_h)\n",
        "        val_data, val_label = prepare_crop_data_new(_validation_path_l,_validation_path_h)\n",
        "        #transpose to match input shape\n",
        "        train_data_t = numpy.transpose(data, (0, 2, 3, 1))\n",
        "        train_label_t = numpy.transpose(label, (0, 2, 3, 1))\n",
        "        val_data_t = numpy.transpose(val_data, (0, 2, 3, 1))\n",
        "        val_label_t = numpy.transpose(val_label, (0, 2, 3, 1))\n",
        "\n",
        "    # Split the data\n",
        "#     train_data_t, val_data_t, train_label_t, val_label_t = train_test_split(train_data_t, train_label_t, test_size=0.33, shuffle= True)\n",
        "\n",
        "    checkpoint = ModelCheckpoint(_checkp_name, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "                                 save_weights_only=False, mode='min')\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    history =  srcnn_model.fit(train_data_t, train_label_t, batch_size=128, validation_data=(val_data_t, val_label_t),\n",
        "                    callbacks=callbacks_list, shuffle=True, epochs=_numEpochs, verbose=0)\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "    plt.savefig(str(_checkp_name)+'_.png')\n",
        "    # srcnn_model.load_weights(\"m_model_adam.h5\")\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXELyzzIDHez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from skimage.measure import compare_ssim as ssim\n",
        "import numpy as np\n",
        "\n",
        "def psnr(target, ref):     \n",
        "    return cv2.PSNR(ref,target)\n",
        "\n",
        "# define function for mean squared error (MSE)\n",
        "def mse(target, ref):\n",
        "    # the MSE between the two images is the sum of the squared difference between the two images\n",
        "    err = np.sum((target.astype('float') - ref.astype('float')) ** 2)\n",
        "    err /= float(target.shape[0] * target.shape[1])\n",
        "    \n",
        "    return err\n",
        "\n",
        "# define function that combines all three image quality metrics\n",
        "def compare_images(target, ref):\n",
        "    scores = []\n",
        "    scores.append(psnr(target, ref))\n",
        "    scores.append(mse(target, ref))\n",
        "    scores.append(ssim(target, ref, multichannel =True))\n",
        "    \n",
        "    return scores\n",
        "\n",
        "\n",
        "def predict(_imgName,_checkp_FileName):\n",
        "    srcnn_model = predict_model()\n",
        "#     srcnn_model.load_weights(\"3051crop_weight_200.h5\")\n",
        "    srcnn_model.load_weights(_checkp_FileName)\n",
        "#     IMG_NAME = \"/content/srcnn_keras_dataset/test/baby_GT.bmp\"\n",
        "  \n",
        "    INPUT_SAVE_NAME = \"input2.jpg\"\n",
        "    OUTPUT_SAVE_NAME = \"pre2.jpg\"\n",
        "\n",
        "\n",
        "    img = cv2.imread(_imgName, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    shape = img.shape\n",
        "    Y_img = cv2.resize(img[:, :, 0], (shape[1] // scale, shape[0] // scale), cv2.INTER_CUBIC)\n",
        "    Y_img = cv2.resize(Y_img, (shape[1], shape[0]), cv2.INTER_CUBIC)\n",
        "    img[:, :, 0] = Y_img\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    cv2.imwrite(INPUT_SAVE_NAME, img)\n",
        "\n",
        "    Y = numpy.zeros((1, img.shape[0], img.shape[1], 1), dtype=float)\n",
        "    Y[0, :, :, 0] = Y_img.astype(float) / 255.\n",
        "    pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
        "    pre[pre[:] > 255] = 255\n",
        "    pre[pre[:] < 0] = 0\n",
        "    pre = pre.astype(numpy.uint8)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    img[6: -6, 6: -6, 0] = pre[0, :, :, 0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    cv2.imwrite(OUTPUT_SAVE_NAME, img)\n",
        "\n",
        "    # psnr calculation:\n",
        "    im_Orig = cv2.imread(_imgName, cv2.IMREAD_COLOR)\n",
        "    im_Orig = cv2.cvtColor(im_Orig, cv2.COLOR_BGR2YCrCb)[6: -6, 6: -6, 0]\n",
        "    print (\"im_Orig:\")\n",
        "    cv2_imshow(im_Orig)\n",
        "    im_upscaled = cv2.imread(INPUT_SAVE_NAME, cv2.IMREAD_COLOR)\n",
        "    im_upscaled = cv2.cvtColor(im_upscaled, cv2.COLOR_BGR2YCrCb)[6: -6, 6: -6, 0]\n",
        "    print (\"im_upscaled bicubic:\")\n",
        "    cv2_imshow(im_upscaled)\n",
        "    im_predicted = cv2.imread(OUTPUT_SAVE_NAME, cv2.IMREAD_COLOR)\n",
        "    im_predicted = cv2.cvtColor(im_predicted, cv2.COLOR_BGR2YCrCb)[6: -6, 6: -6, 0]\n",
        "    print (\"SR:\")\n",
        "    cv2_imshow(im_predicted)\n",
        "    \n",
        "    print (\"bicubic: (psnr,mse,ssim)\")\n",
        "    print (compare_images(im_Orig, im_upscaled))\n",
        "    print (\"SRCNN : (psnr,mse,ssim)\")\n",
        "    print (compare_images(im_Orig, im_predicted))\n",
        "    print (\"Orig Vs Orig: (psnr,mse,ssim)\")\n",
        "    print (compare_images(im_Orig, im_Orig))\n",
        "    \n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQVJ5qnxiWGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare h5 data files:\n",
        "import shutil\n",
        "if (False):\n",
        "    _train_path_H = '/content/Dataset_casia_V1_HR_train/'\n",
        "    _train_path_L = '/content/Dataset_casia_V1_LR_train/'\n",
        "    data, label = prepare_crop_data_new(_train_path_L,_train_path_H)\n",
        "    write_hdf5(data, label, \"crop_train_Dataset_casia_V1_4.h5\")\n",
        "\n",
        "\n",
        "    _validation_path_H = '/content/Dataset_casia_V1_HR_test/'\n",
        "    _validation_path_L = '/content/Dataset_casia_V1_LR_test/'\n",
        "    data, label = prepare_crop_data_new(_validation_path_L,_validation_path_H)\n",
        "    write_hdf5(data, label, \"crop_val_Dataset_casia_V1_4.h5\")\n",
        "\n",
        "\n",
        "    !cp -avr \"/content/crop_train_Dataset_casia_V1_4.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/' \n",
        "    !cp -avr \"/content/crop_val_Dataset_casia_V1_4.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/' \n",
        "\n",
        "    _train_path_H = '/content/Dataset_berc_h/data/train/'\n",
        "    _train_path_L = '/content/Dataset_berc_l/data/train/'\n",
        "    data, label = prepare_crop_data_new(_train_path_L,_train_path_H)\n",
        "    write_hdf5(data, label, \"crop_train_Dataset_berc.h5\")\n",
        "\n",
        "\n",
        "    _validation_path_H = '/content/Dataset_berc_h/data/validation/'\n",
        "    _validation_path_L = '/content/Dataset_berc_l/data/validation/'\n",
        "    data, label = prepare_crop_data_new(_validation_path_L,_validation_path_H)\n",
        "    write_hdf5(data, label, \"crop_val_Dataset_berc.h5\")\n",
        "    print('done berc ')\n",
        "\n",
        "    _train_path_H = '/content/Dataset_casia_h/data/train/'\n",
        "    _train_path_L = '/content/Dataset_casia_l/data/train/'\n",
        "    data, label = prepare_crop_data_new(_train_path_L,_train_path_H)\n",
        "    write_hdf5(data, label, \"crop_train_Dataset_casia.h5\")\n",
        "\n",
        "    _validation_path_H = '/content/Dataset_casia_h/data/validation/'\n",
        "    _validation_path_L = '/content/Dataset_casia_l/data/validation/'\n",
        "    data, label = prepare_crop_data_new(_validation_path_L,_validation_path_H)\n",
        "    write_hdf5(data, label, \"crop_val_Dataset_casia.h5\")\n",
        "    print('done casia')\n",
        "\n",
        "    _train_path_H = '/content/Dataset_ndcld_h/data/train/'\n",
        "    _train_path_L = '/content/Dataset_ndcld_l/data/train/'\n",
        "    data, label = prepare_crop_data_new(_train_path_L,_train_path_H)\n",
        "    write_hdf5(data, label, \"crop_train_Dataset_ndcld.h5\")\n",
        "\n",
        "\n",
        "    _validation_path_H = '/content/Dataset_ndcld_h/data/validation/'\n",
        "    _validation_path_L = '/content/Dataset_ndcld_l/data/validation/'\n",
        "    data, label = prepare_crop_data_new(_validation_path_L,_validation_path_H)\n",
        "    write_hdf5(data, label, \"crop_val_Dataset_ndcld.h5\")\n",
        "    print('done ndcld')\n",
        "\n",
        "    _train_path_H = '/content/CombinedDataset_h/data/train/'\n",
        "    _train_path_L = '/content/CombinedDataset_l/data/train/'\n",
        "    data, label = prepare_crop_data_new(_train_path_L,_train_path_H)\n",
        "    write_hdf5(data, label, \"crop_train_CombinedDataset.h5\")\n",
        "\n",
        "\n",
        "    _validation_path_H = '/content/CombinedDataset_h/data/validation/'\n",
        "    _validation_path_L = '/content/CombinedDataset_l/data/validation/'\n",
        "    data, label = prepare_crop_data_new(_validation_path_L,_validation_path_H)\n",
        "    write_hdf5(data, label, \"crop_val_CombinedDataset.h5\")\n",
        "    print('done combined')\n",
        "\n",
        "#casia V1 dataset:\n",
        "\n",
        "# casia V1\n",
        "    _train_path_H = '/content/Dataset_casia_V1_HR/data/train/'\n",
        "    _validation_path_H =  '/content/Dataset_casia_V1_HR/data/validation/'\n",
        "\n",
        "    scales = [1.5,2.0,3.0,4.0,5.0,6.0, 8.0,9.0,10.0,11.0,12.0,14.0,16.0]\n",
        "    for scale in scales:\n",
        "        crop_train_Casia_V1_dataset_name = 'crop_train_Casia_V1_dataset_'  + str(scale) +'.h5'\n",
        "        crop_val_Casia_V1_dataset_name = 'crop_val_Casia_V1_dataset_'  + str(scale) +'.h5'\n",
        "\n",
        "        print('scale =' ,scale,' ' ,crop_train_Casia_V1_dataset_name,' ' ,crop_val_Casia_V1_dataset_name  )\n",
        "\n",
        "        _train_path_L = '/content/Dataset_casia_V1_LR_' + str(scale) + '/data/train/'\n",
        "\n",
        "        data, label = prepare_crop_data_new(_train_path_L,_train_path_H)\n",
        "        write_hdf5(data, label, crop_train_Casia_V1_dataset_name)\n",
        "        print('done train casia V1')\n",
        "        \n",
        "        _validation_path_L = '/content/Dataset_casia_V1_LR_' + str(scale) + '/data/validation/'\n",
        "\n",
        "        data, label = prepare_crop_data_new(_validation_path_L,_validation_path_H)\n",
        "        write_hdf5(data, label, crop_val_Casia_V1_dataset_name)\n",
        "        print('done validation casia V1')\n",
        "        # copy to drive\n",
        "        # !mkdir '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/' \n",
        "        \n",
        "\n",
        "        shutil.copy2 ('/content/'+str(crop_train_Casia_V1_dataset_name), '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/')  \n",
        "        shutil.copy2 ('/content/'+str(crop_val_Casia_V1_dataset_name), '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/') \n",
        "        print('done copy to drive' ,'scale =' ,scale, )\n",
        "        # !cp -avr \"/content/crop_train_Casia_V1_dataset_8.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/' \n",
        "        # !cp -avr \"/content/crop_val_Casia_V1_dataset_8.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/'     \n",
        "\n",
        "\n",
        "# using orig prep func:\n",
        "    _train_path_H = '/content/Dataset_casia_V1_HR_train/'\n",
        "    data, label = prepare_crop_data(_train_path_H)\n",
        "    write_hdf5(data, label, \"crop_train_orig_Casia_V1_dataset.h5\")\n",
        "    _validation_path_H =  '/content/Dataset_casia_V1_HR_test/'\n",
        "    data, label = prepare_crop_data(_validation_path_H)\n",
        "    write_hdf5(data, label, \"crop_val_orig_Casia_V1_dataset.h5\")\n",
        "     # copy to drive\n",
        "    # !mkdir '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/'\n",
        "    !cp -avr \"/content/crop_train_orig_Casia_V1_dataset.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/' \n",
        "    !cp -avr \"/content/crop_val_orig_Casia_V1_dataset.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/' \n",
        "\n",
        " \n",
        "# !rm -rf '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/*.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccE2aFQINrx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copy from drive saved weights and h5 datasets\n",
        "!cp -avr '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/.' '/content/saved_datasets_h5/'\n",
        "!cp -avr  '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_w/.' '/content/saved_w/'\n",
        "print('done copy weights and datasets ')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sREjXiUko9-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare h5 dataset files (maybe saves memory )\n",
        "# Train:\n",
        "\n",
        "CHEKPOINT_NAME =\"SRCNN_check_Dataset_berc_30Ep.h5\"\n",
        "NUM_EPOCHS = 30;\n",
        "H5_DATASET_TRAIN = '/content/crop_train_Dataset_berc.h5'\n",
        "H5_DATASET_VAL = '/content/crop_val_Dataset_berc.h5'\n",
        "load_h5_weights_Toggle = True\n",
        "train(H5_DATASET_TRAIN,H5_DATASET_VAL,CHEKPOINT_NAME,NUM_EPOCHS,load_h5_weights_Toggle,H5_DATASET_TRAIN,H5_DATASET_VAL)\n",
        "!cp -avr \"SRCNN_check_Dataset_berc_30Ep.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_w/'\n",
        "print('done berc')\n",
        "#\n",
        "DATA_PATH = \"Dataset_casia/\"\n",
        "CHEKPOINT_NAME =\"SRCNN_check_Dataset_casia_30Ep.h5\"\n",
        "NUM_EPOCHS = 30;\n",
        "H5_DATASET_TRAIN = '/content/crop_train_Dataset_casia.h5'\n",
        "H5_DATASET_VAL = '/content/crop_val_Dataset_casia.h5'\n",
        "train(H5_DATASET_TRAIN,H5_DATASET_VAL,CHEKPOINT_NAME,NUM_EPOCHS,load_h5_weights_Toggle,H5_DATASET_TRAIN,H5_DATASET_VAL)\n",
        "!cp -avr \"SRCNN_check_Dataset_casia_30Ep.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_w/'\n",
        "print('done casia')\n",
        "#\n",
        "DATA_PATH = \"Dataset_ndcld/\"\n",
        "CHEKPOINT_NAME =\"SRCNN_check_Dataset_ndcld_30Ep.h5\"\n",
        "NUM_EPOCHS = 30;\n",
        "H5_DATASET_TRAIN = '/content/crop_train_Dataset_ndcld.h5'\n",
        "H5_DATASET_VAL = '/content/crop_val_Dataset_ndcld.h5'\n",
        "train(H5_DATASET_TRAIN,H5_DATASET_VAL,CHEKPOINT_NAME,NUM_EPOCHS,load_h5_weights_Toggle,H5_DATASET_TRAIN,H5_DATASET_VAL)\n",
        "!cp -avr \"SRCNN_check_Dataset_ndcld_30Ep.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_w/'\n",
        "print('done ndcld')\n",
        "#\n",
        "DATA_PATH = \"CombinedDataset/\"\n",
        "CHEKPOINT_NAME =\"SRCNN_check_CombinedDataset_35Ep.h5\"\n",
        "NUM_EPOCHS = 35;\n",
        "H5_DATASET_TRAIN = '/content/crop_train_CombinedDataset.h5'\n",
        "H5_DATASET_VAL = '/content/crop_val_CombinedDataset.h5'\n",
        "train(H5_DATASET_TRAIN,H5_DATASET_VAL,CHEKPOINT_NAME,NUM_EPOCHS,load_h5_weights_Toggle,H5_DATASET_TRAIN,H5_DATASET_VAL)\n",
        "!cp -avr \"SRCNN_check_CombinedDataset_35Ep.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_w/'\n",
        "print('done CombinedDataset')\n",
        "   \n",
        "# casia V1   \n",
        "load_h5_weights_Toggle = True  \n",
        "DATA_PATH = \"Casia_V1_dataset/\" \n",
        "scales = [1.5,2.0,3.0,4.0,5.0,6.0, 8.0,9.0,10.0,11.0,12.0,14.0,16.0]\n",
        "for scale in scales:\n",
        "    NUM_EPOCHS = 40;\n",
        "    H5_DATASET_TRAIN = '/content/crop_train_Casia_V1_dataset_' +  str(scale) + '.h5'\n",
        "    H5_DATASET_VAL = '/content/crop_val_Casia_V1_dataset_' +  str(scale) + '.h5'\n",
        "    CHEKPOINT_NAME = \"SRCNN_check_Dataset_casia_V1_multi_Scale_\" + str(scale) + '_numEp_'+ str(NUM_EPOCHS)+'.h5'\n",
        "    print('training ... scale =' ,scale,' ' ,H5_DATASET_TRAIN,' ' ,H5_DATASET_VAL, ' ',CHEKPOINT_NAME  )\n",
        "\n",
        "    train(H5_DATASET_TRAIN,H5_DATASET_VAL,CHEKPOINT_NAME,NUM_EPOCHS,load_h5_weights_Toggle,H5_DATASET_TRAIN,H5_DATASET_VAL)\n",
        "    # !cp -avr \"SRCNN_check_Dataset_casia_V1_Scale4_40ep.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_w/'\n",
        "    shutil.copy2 ('/content/'+str(CHEKPOINT_NAME), '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_w/')  \n",
        "    print('done training Casia_V1_dataset')\n",
        "\n",
        " \n",
        "# !mkdir '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_train_images/'\n",
        " for scale in scales:    \n",
        "    CHEKPOINT_NAME = \"SRCNN_check_Dataset_casia_V1_multi_Scale_\" + str(scale) + '_numEp_'+ str(NUM_EPOCHS)+'.h5'              \n",
        "    shutil.copy2 ('/content/'+str(CHEKPOINT_NAME) + '_.png', '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_train_images/')  \n",
        "    print('/content/'+str(CHEKPOINT_NAME) + '_.png' , ' copied')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nQbg7njv5ks1",
        "colab": {}
      },
      "source": [
        "# copy saved w to drive\n",
        "\n",
        "print('saved_weights copied')\n",
        "if (False):\n",
        "    # copy saved datasets to drive\n",
        "    !cp -avr \"/content/crop_train_Dataset_berc.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/'\n",
        "    !cp -avr \"/content/crop_val_Dataset_berc.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/'\n",
        "    !cp -avr \"/content/crop_train_Dataset_casia.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/'\n",
        "    !cp -avr \"/content/crop_val_Dataset_casia.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/'\n",
        "    !cp -avr \"/content/crop_train_Dataset_ndcld.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/'\n",
        "    !cp -avr \"/content/crop_val_Dataset_ndcld.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/'\n",
        "    !cp -avr \"/content/crop_train_CombinedDataset.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/'\n",
        "    !cp -avr \"/content/crop_val_CombinedDataset.h5\" '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/'\n",
        "\n",
        "    print('saved_weights copied')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8EcF85zpFZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!cp -avr '/content/Dataset_casia_V1_HR/data/validation/046_2_4.jpg'  '/content/1.jpg'\n",
        "IMG_NAME_H = \"1.jpg\"\n",
        "!cp -avr '/content/Dataset_casia_V1_LR_8/data/validation/046_2_4.jpg'  '/content/2.jpg'\n",
        "IMG_NAME_L = \"2.jpg\"\n",
        "# IMG_NAME = \"/content/Validation_old/live-850-068_000_i_to_00_00_000_01_00_l_20050928131705.jpg\"\n",
        "# IMG_NAME = \"/content/Dataset_ndcld/data/validation/testing-live-05871d852.jpg\"\n",
        "\n",
        "# CHEKPOINT_NAME = '/content/SRCNN_check_casia_50Ep_L0_00033.h5'\n",
        "# CHEKPOINT_NAME = '/content/SRCNN_check_ber_50Ep_L0_00089.h5'\n",
        "\n",
        "CHEKPOINT_NAME =\"/content/SRCNN_check_Dataset_casia_V1_Scale8_40ep.h5\"\n",
        "\n",
        "# predict:\n",
        "# predict(IMG_NAME_H,CHEKPOINT_NAME)\n",
        "\n",
        "predict_clean(IMG_NAME_L,IMG_NAME_H,CHEKPOINT_NAME)\n",
        "#   try another pass through net\n",
        "    srcnn_model = predict_model()\n",
        "    srcnn_model.load_weights(CHEKPOINT_NAME)\n",
        "    img = cv2.imread('/content/pre_pre2.jpg', cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    shape = img.shape\n",
        "    Y_img = img[:, :, 0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    cv2_imshow(img)\n",
        "    \n",
        "    Y = numpy.zeros((1, img.shape[0], img.shape[1], 1), dtype=float)\n",
        "    Y[0, :, :, 0] = Y_img.astype(float) / 255.\n",
        "    pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
        "    pre[pre[:] > 255] = 255\n",
        "    pre[pre[:] < 0] = 0\n",
        "    pre = pre.astype(numpy.uint8)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    img[6: -6, 6: -6, 0] = pre[0, :, :, 0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    cv2.imwrite('/content/pre_pre_pre2.jpg', img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg_3FPbak6gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TOFIX\n",
        "import os \n",
        "# scale = 4\n",
        "def predict_clean(_imgNameLow,_imgNameHigh,_checkp_FileName,scale):\n",
        "    srcnn_model = predict_model()\n",
        "#   srcnn_model.load_weights(\"3051crop_weight_200.h5\")\n",
        "    srcnn_model.load_weights(_checkp_FileName)\n",
        "#   IMG_NAME = \"/content/srcnn_keras_dataset/test/baby_GT.bmp\"\n",
        "    OUT_PATH = '/content/SR_Result_x8'\n",
        "    INPUT_SAVE_NAME = \"input2.jpg\"\n",
        "    OUTPUT_SAVE_NAME = \"pre2.jpg\"\n",
        "\n",
        "    img = cv2.imread(_imgNameLow, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    shape = img.shape\n",
        "    Y_img = cv2.resize(img[:, :, 0], (shape[1] * scale, shape[0] * scale), cv2.INTER_CUBIC)\n",
        "    img = cv2.resize(img, (shape[1] * scale, shape[0] * scale), cv2.INTER_CUBIC)\n",
        "    img[:, :, 0] = Y_img\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    cv2.imwrite(INPUT_SAVE_NAME, img)\n",
        "    cv2_imshow(img)\n",
        "    \n",
        "    Y = numpy.zeros((1, img.shape[0], img.shape[1], 1), dtype=float)\n",
        "    Y[0, :, :, 0] = Y_img.astype(float) / 255.\n",
        "    pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
        "    pre[pre[:] > 255] = 255\n",
        "    pre[pre[:] < 0] = 0\n",
        "    pre = pre.astype(numpy.uint8)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    img[6: -6, 6: -6, 0] = pre[0, :, :, 0]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "    cv2.imwrite(OUTPUT_SAVE_NAME, img)\n",
        "\n",
        "    # psnr calculation:\n",
        "    im_Orig = cv2.imread(_imgNameHigh, cv2.IMREAD_COLOR)\n",
        "    im_Orig = cv2.cvtColor(im_Orig, cv2.COLOR_BGR2YCrCb)[6: -6, 6: -6, 0]\n",
        "    print (\"im_Orig:\")\n",
        "    cv2_imshow(im_Orig)\n",
        "    im_upscaled = cv2.imread(INPUT_SAVE_NAME, cv2.IMREAD_COLOR)\n",
        "    im_upscaled = cv2.cvtColor(im_upscaled, cv2.COLOR_BGR2YCrCb)[6: -6, 6: -6, 0]\n",
        "    print (\"im_upscaled bicubic:\")\n",
        "    cv2_imshow(im_upscaled)\n",
        "    im_predicted = cv2.imread(OUTPUT_SAVE_NAME, cv2.IMREAD_COLOR)\n",
        "    im_predicted = cv2.cvtColor(im_predicted, cv2.COLOR_BGR2YCrCb)[6: -6, 6: -6, 0]\n",
        "    print (\"SR:\")\n",
        "    cv2_imshow(im_predicted)\n",
        "    \n",
        "    print (\"bicubic: (psnr,mse,ssim)\")\n",
        "    print (compare_images(im_Orig, im_upscaled))\n",
        "    print (\"SRCNN : (psnr,mse,ssim)\")\n",
        "    print (compare_images(im_Orig, im_predicted))\n",
        "    print (\"Orig Vs Orig: (psnr,mse,ssim)\")\n",
        "    print (compare_images(im_Orig, im_Orig))\n",
        "    \n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akRKLzbpHNyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TOFIX\n",
        "import os \n",
        "import time\n",
        "import math\n",
        "\n",
        "def generate_sr_images(_imgNameLowDir,_checkp_FileName,scale):\n",
        "    srcnn_model = predict_model()\n",
        "    srcnn_model.load_weights(_checkp_FileName)\n",
        "\n",
        "    if not os.path.exists(_imgNameLowDir):\n",
        "        raise OSError('_imgNameLowDir does not exist')    \n",
        "    out_dir = _imgNameLowDir + '/SR_' + str(scale)\n",
        "    if not os.path.exists(out_dir):\n",
        "        os.makedirs(out_dir)\n",
        "\n",
        "    names = [f for f in os.listdir(_imgNameLowDir) if f.endswith(\".jpg\")]\n",
        "    names = sorted(names)\n",
        "    nums = names.__len__()\n",
        "    counter = 0\n",
        "\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "    textfile = open('SR_GEN_LOG' + timestr +'.txt', 'w') \n",
        "  \n",
        "    for i in range(nums):\n",
        "        name =os.path.join(_imgNameLowDir,names[i])\n",
        "        # print('name' ,name)\n",
        "        img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "        shape = img.shape\n",
        "        Y_img = cv2.resize(img[:, :, 0], (math.floor(shape[1] * scale), math.floor(shape[0] * scale)), cv2.INTER_CUBIC)\n",
        "        img = cv2.resize(img, (math.floor(shape[1] * scale), math.floor(shape[0] * scale)), cv2.INTER_CUBIC)\n",
        "        img[:, :, 0] = Y_img\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "        #\n",
        "        Y = numpy.zeros((1, img.shape[0], img.shape[1], 1), dtype=float)\n",
        "        Y[0, :, :, 0] = Y_img.astype(float) / 255.\n",
        "        pre = srcnn_model.predict(Y, batch_size=1) * 255.\n",
        "        pre[pre[:] > 255] = 255\n",
        "        pre[pre[:] < 0] = 0\n",
        "        pre = pre.astype(numpy.uint8)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "        img[6: -6, 6: -6, 0] = pre[0, :, :, 0]\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "        cv2.imwrite(os.path.join(out_dir,names[i]), img)\n",
        "\n",
        "        counter  += 1   \n",
        "        print(str(counter) + '# file:' + names[i] + '\\n', file = textfile) \n",
        "        #TBD add validation print\n",
        "    # print('Copied ' + str(counter) + out_dir)\n",
        "    textfile.close() \n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQxgeGDHS1BY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf 'low_res_ndcld'\n",
        "!rm -rf 'low_res_casia'\n",
        "!rm -rf 'low_res_berc'\n",
        "!rm -rf 'low_res_combined'\n",
        "#copy split dataset  from drive  validation:\n",
        "# low res val\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/Dataset_ndcld_split_l/validation/' low_res_ndcld\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/Dataset_casia_split_l/validation/' low_res_casia\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/Dataset_berc_split_l/validation/' low_res_berc\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/CombinedDataset_split_l/validation/' low_res_combined\n",
        "print('copy from drive done')\n",
        "# high res val\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/Dataset_ndcld_split_h/validation/' high_res_ndcld\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/Dataset_casia_split_h/validation/' high_res_casia\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/Dataset_berc_split_h/validation/' high_res_berc\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/CombinedDataset_split_h/validation/' high_res_combined\n",
        "print('copy from drive done')\n",
        "#copy split dataset  from drive  train:\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/Dataset_ndcld_split_l/train/' low_res_ndcld_train\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/Dataset_casia_split_l/train/' low_res_casia_train\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/Dataset_berc_split_l/train/' low_res_berc_train\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/CombinedDataset_split_l/train/' low_res_combined_train\n",
        "print('copy from drive train done')\n",
        "# high res val\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/Dataset_ndcld_split_h/train/' high_res_ndcld_train\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/Dataset_casia_split_h/train/' high_res_casia_train\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/Dataset_berc_split_h/train/' high_res_berc_train\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Iris_Dataset/CombinedDataset_split_h/train/' high_res_combined_train\n",
        "print('copy from drive train done')\n",
        "\n",
        "# casia V1:\n",
        "#copy split dataset  from drive  train+ val:\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Dataset_casia_V1_split_h/train/' '/content/Dataset_casia_V1_HR_train'\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Dataset_casia_V1_split_h/validation/' '/content/Dataset_casia_V1_HR_test'\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Dataset_casia_V1_split_l/train/' '/content/Dataset_casia_V1_LR_train'\n",
        "!cp -ar '/content/drive/My Drive/Toar2/Thesis/Iris_recog/Dataset_casia_V1_split_l/validation/' '/content/Dataset_casia_V1_LR_test'\n",
        "print('copy from drive train and val casia V1 done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amr--tjHSxTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --------------------------------------------------------------------\n",
        "# gen SR for validation (test data)\n",
        "# --------------------------------------------------------------------\n",
        "\n",
        "# CHEKPOINT_NAME =\"/content/saved_w/SRCNN_check_Dataset_casia_30Ep.h5\"\n",
        "# LR_IMG_DIR = '/content/low_res_casia'\n",
        "# generate_sr_images(LR_IMG_DIR,CHEKPOINT_NAME)\n",
        "# print('done casia')\n",
        "scale = 4;\n",
        "CHEKPOINT_NAME =\"/content/saved_w/SRCNN_check_Dataset_berc_30Ep.h5\"\n",
        "LR_IMG_DIR = '/content/low_res_berc'\n",
        "generate_sr_images(LR_IMG_DIR,CHEKPOINT_NAME,scale)\n",
        "print('done berc')\n",
        "CHEKPOINT_NAME =\"/content/saved_w/SRCNN_check_Dataset_ndcld_30Ep.h5\"\n",
        "LR_IMG_DIR = '/content/low_res_ndcld'\n",
        "generate_sr_images(LR_IMG_DIR,CHEKPOINT_NAME,scale)\n",
        "print('done ndckd')\n",
        "CHEKPOINT_NAME =\"/content/saved_w/SRCNN_check_CombinedDataset_35Ep.h5\"\n",
        "LR_IMG_DIR = '/content/low_res_combined'\n",
        "generate_sr_images(LR_IMG_DIR,CHEKPOINT_NAME,scale)\n",
        "print('done combined')\n",
        "\n",
        "# # remove unnecesary jpeg files from all datasets  to save disk space:\n",
        "# # clean all scales LR:\n",
        "# import os\n",
        "# scales = [1.5,2.0,3.0,4.0,5.0,6.0, 8.0,9.0,10.0,11.0,12.0,14.0,16.0]\n",
        "# for scale in scales:\n",
        "#     dir_name =  '/content/Dataset_casia_V1_LR_' + str(scale)\n",
        "#     test = os.listdir(dir_name)\n",
        "#     for item in test:\n",
        "#         if item.endswith(\".jpg\"):\n",
        "#             os.remove(os.path.join(dir_name, item))\n",
        "# # clean HR:\n",
        "# dir_name =  '/content/Dataset_casia_V1_HR' \n",
        "# test = os.listdir(dir_name)\n",
        "# for item in test:\n",
        "#     if item.endswith(\".jpg\"):\n",
        "#         os.remove(os.path.join(dir_name, item))\n",
        "\n",
        "# casia V1  :\n",
        "NUM_EPOCHS = 40;\n",
        "scales = [1.5,2.0,3.0,4.0,5.0,6.0, 8.0,9.0,10.0,11.0,12.0,14.0,16.0]\n",
        "for scale in scales:\n",
        "    \n",
        "    LR_IMG_DIR = '/content/Dataset_casia_V1_LR_' + str(scale) + '/data/validation' # validation lr images\n",
        "    CHEKPOINT_NAME = \"SRCNN_check_Dataset_casia_V1_multi_Scale_\" + str(scale) + '_numEp_'+ str(NUM_EPOCHS)+'.h5'\n",
        "    print('generate_sr_images ... scale =' ,scale,' ' ,LR_IMG_DIR,' ',CHEKPOINT_NAME  )\n",
        "    generate_sr_images(LR_IMG_DIR,CHEKPOINT_NAME,scale)\n",
        "    print('done')\n",
        "\n",
        "# !rm -rf '/content/Dataset_casia_V1_LR_test/SR'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Zwc_2zRci4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copy from drive saved weights and h5 datasets\n",
        "!cp -avr '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_datasets_h5/.' '/content/saved_datasets_h5/'\n",
        "!cp -avr '/content/drive/My Drive/Toar2/Thesis/Iris_recog/saved_w/.' '/content/saved_w/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igSf2p8pUrEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --------------------------------------------------------------------\n",
        "# gen SR for train data\n",
        "# --------------------------------------------------------------------\n",
        "\n",
        "# CHEKPOINT_NAME =\"/content/saved_w/SRCNN_check_Dataset_casia_30Ep.h5\"\n",
        "# LR_IMG_DIR = '/content/low_res_casia_train'\n",
        "# generate_sr_images(LR_IMG_DIR,CHEKPOINT_NAME)\n",
        "# print('done casia')\n",
        "CHEKPOINT_NAME =\"/content/saved_w/SRCNN_check_Dataset_berc_30Ep.h5\"\n",
        "LR_IMG_DIR = '/content/low_res_berc_train'\n",
        "generate_sr_images(LR_IMG_DIR,CHEKPOINT_NAME)\n",
        "print('done berc')\n",
        "CHEKPOINT_NAME =\"/content/saved_w/SRCNN_check_Dataset_ndcld_30Ep.h5\"\n",
        "LR_IMG_DIR = '/content/low_res_ndcld_train'\n",
        "generate_sr_images(LR_IMG_DIR,CHEKPOINT_NAME)\n",
        "print('done ndckd')\n",
        "CHEKPOINT_NAME =\"/content/saved_w/SRCNN_check_CombinedDataset_35Ep.h5\"\n",
        "LR_IMG_DIR = '/content/low_res_combined_train'\n",
        "generate_sr_images(LR_IMG_DIR,CHEKPOINT_NAME)\n",
        "print('done combined')\n",
        "\n",
        "CHEKPOINT_NAME =\"\"\n",
        "LR_IMG_DIR = '/content/low_res_combined_train'\n",
        "generate_sr_images(LR_IMG_DIR,CHEKPOINT_NAME)\n",
        "print('done combined')\n",
        "\n",
        "# casia V1  :\n",
        "NUM_EPOCHS = 40;\n",
        "scales = [1.5,2.0,3.0,4.0,5.0,6.0, 8.0,9.0,10.0,11.0,12.0,14.0,16.0]\n",
        "for scale in scales:\n",
        "    \n",
        "    LR_IMG_DIR = '/content/Dataset_casia_V1_LR_' + str(scale) + '/data/train' # train lr images\n",
        "    CHEKPOINT_NAME = \"SRCNN_check_Dataset_casia_V1_multi_Scale_\" + str(scale) + '_numEp_'+ str(NUM_EPOCHS)+'.h5'\n",
        "    print('generate_sr_images ... scale =' ,scale,' ' ,LR_IMG_DIR,' ',CHEKPOINT_NAME  )\n",
        "    generate_sr_images(LR_IMG_DIR,CHEKPOINT_NAME,scale)\n",
        "    print('done')\n",
        "\n",
        "\n",
        "# !rm -rf '/content/Dataset_casia_V1_LR_train/SR'\n",
        "# !rm -rf '/content/Dataset_casia_V1_LR_test/SR'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga81Y9fnhGAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy validation (test) SR images to drive\n",
        "# !cp -avr '/content/low_res_casia/SR' '/content/drive/My Drive/Toar2/Thesis/Iris_recog/SR_Scaled_test_images/casia_test_sr/'\n",
        "# print('done')\n",
        "!cp -avr '/content/low_res_berc/SR' '/content/drive/My Drive/Toar2/Thesis/Iris_recog/SR_Scaled_test_images/berc_test_sr/'\n",
        "print('done')\n",
        "!cp -ar '/content/low_res_ndcld/SR' '/content/drive/My Drive/Toar2/Thesis/Iris_recog/SR_Scaled_test_images/ndcld_test_sr/'\n",
        "print('done')\n",
        "!cp -ar '/content/low_res_combined/SR' '/content/drive/My Drive/Toar2/Thesis/Iris_recog/SR_Scaled_test_images/combined_test_sr/'\n",
        "print('done')\n",
        "\n",
        "# casia V1  :\n",
        "NUM_EPOCHS = 40;\n",
        "scales = [1.5,2.0,3.0,4.0,5.0,6.0, 8.0,9.0,10.0,11.0,12.0,14.0,16.0]\n",
        "for scale in scales:\n",
        "    # train \n",
        "    path_train_SR_scaled = '/content/Dataset_casia_V1_LR_' + str(scale) + '/data/train/SR_' + str(scale) # train sr images\n",
        "    path_train_SR_scaled_drive = 'Dataset_casia_V1_multi_split_TRAIN_SR_'+ str(scale)\n",
        "    print( path_train_SR_scaled  )\n",
        "    # test (validation)\n",
        "    path_test_SR_scaled = '/content/Dataset_casia_V1_LR_' + str(scale) + '/data/validation/SR_' + str(scale) # train sr images\n",
        "    path_test_SR_scaled_drive = 'Dataset_casia_V1_multi_split_TEST_SR_'+ str(scale)\n",
        "    print( path_test_SR_scaled  )\n",
        "    #copy to drive:\n",
        "    copytree(path_train_SR_scaled , os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' ,path_train_SR_scaled_drive))\n",
        "    print( 'done copy train'  )\n",
        "    copytree(path_test_SR_scaled , os.path.join('/content/drive/My Drive/Toar2/Thesis/Iris_recog/' ,path_test_SR_scaled_drive))\n",
        "    print( 'done copy test'  )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYibheIvWEmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy train () SR images to drive\n",
        "# !mkdir '/content/drive/My Drive/Toar2/Thesis/Iris_recog/SR_Scaled_train_images/combined_train_sr/'\n",
        "\n",
        "!cp -avr '/content/low_res_casia_train/SR' '/content/drive/My Drive/Toar2/Thesis/Iris_recog/SR_Scaled_train_images/casia_train_sr/'\n",
        "print('done train')\n",
        "!cp -avr '/content/low_res_berc_train/SR' '/content/drive/My Drive/Toar2/Thesis/Iris_recog/SR_Scaled_train_images/berc_train_sr/'\n",
        "print('done train')\n",
        "!cp -ar '/content/low_res_ndcld_train/SR' '/content/drive/My Drive/Toar2/Thesis/Iris_recog/SR_Scaled_train_images/ndcld_train_sr/'\n",
        "print('done train')\n",
        "!cp -ar '/content/low_res_combined_train/SR' '/content/drive/My Drive/Toar2/Thesis/Iris_recog/SR_Scaled_train_images/combined_train_sr/'\n",
        "print('done train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sze-azhUJte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def print_error_statistics(_imgNameLow_Dir,_imgNameHigh_Dir,_imgNameSR_Dir,dataset_name,scale):\n",
        "    \n",
        "    names = [f for f in os.listdir(_imgNameLow_Dir) if f.endswith(\".jpg\")]\n",
        "    names = sorted(names)\n",
        "    nums = names.__len__()\n",
        "    counter = 0\n",
        "\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    textfile = open('RESULT_SR_VS_ORIG_STATISTICS_' + dataset_name + '_scale_'+ str(scale)+ '_' + timestr +'.txt', 'w') \n",
        "    print('----statistics for:  +' + dataset_name+ 'dataset' + '\\n\\n', file = textfile) \n",
        "    for i in range(nums):\n",
        "        name_low =os.path.join(_imgNameLow_Dir,names[i])\n",
        "        name_high =os.path.join(_imgNameHigh_Dir,names[i])\n",
        "        name_SR =os.path.join(_imgNameSR_Dir,names[i])\n",
        "        img_l = cv2.imread(name_low, cv2.IMREAD_COLOR)\n",
        "        img_h = cv2.imread(name_high, cv2.IMREAD_COLOR)\n",
        "        img_sr = cv2.imread(name_SR, cv2.IMREAD_COLOR)\n",
        "        shape = img_l.shape\n",
        "        im_l_upscaled = cv2.cvtColor(img_l, cv2.COLOR_BGR2YCrCb)\n",
        "        im_l_upscaled = cv2.resize(im_l_upscaled[:, :, 0], (math.floor(shape[1] * scale), math.floor(shape[0] * scale)), cv2.INTER_CUBIC)[6: -6, 6: -6]\n",
        "\n",
        "        img_h = cv2.cvtColor(img_h, cv2.COLOR_BGR2YCrCb)[6: -6, 6: -6, 0]\n",
        "        img_sr = cv2.cvtColor(img_sr, cv2.COLOR_BGR2YCrCb)[6: -6, 6: -6, 0]\n",
        "       \n",
        "        if (i == 1):\n",
        "            print (\"im_l_upscaled:\")\n",
        "            cv2_imshow(im_l_upscaled)\n",
        "            print (\"img_h:\")\n",
        "            cv2_imshow(img_h)\n",
        "            print (\"img_sr:\")\n",
        "            cv2_imshow(img_sr)\n",
        "        print(\"filename: \" + str( names[i] ) + '\\n', file = textfile)\n",
        "        print(\"Orig Vs biCubic(CV2) upscaled: (psnr,mse,ssim)\" + str( compare_images(img_h, im_l_upscaled)) + '\\n', file = textfile) \n",
        "        print(\"orig Vs SR: (psnr,mse,ssim)\" + str( compare_images(img_h, img_sr)  ) + '\\n', file = textfile) \n",
        "        print(\"Orig Vs Orig: (psnr,mse,ssim)\" + str( compare_images(img_h, img_h)   ) + '\\n', file = textfile)\n",
        "        print(\"-------------------------------------\" + '\\n', file = textfile) \n",
        "        \n",
        "    textfile.close() \n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kQxTnCOiHVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run statistis on all *validation* datasets and save log file\n",
        "scale = 4;\n",
        "_imgNameLow_Dir = '/content/low_res_casia/'\n",
        "_imgNameHigh_Dir = '/content/high_res_casia/'\n",
        "_imgNameSR_Dir  = '/content/low_res_casia/SR/'\n",
        "print_error_statistics(_imgNameLow_Dir,_imgNameHigh_Dir,_imgNameSR_Dir,\"casia\",scale)\n",
        "print('casia')\n",
        "\n",
        "_imgNameLow_Dir = '/content/low_res_berc/'\n",
        "_imgNameHigh_Dir = '/content/high_res_berc/'\n",
        "_imgNameSR_Dir  = '/content/low_res_berc/SR/'\n",
        "print_error_statistics(_imgNameLow_Dir,_imgNameHigh_Dir,_imgNameSR_Dir,\"berc\",scale)\n",
        "print('berc')\n",
        "\n",
        "_imgNameLow_Dir = '/content/low_res_ndcld/'\n",
        "_imgNameHigh_Dir = '/content/high_res_ndcld/'\n",
        "_imgNameSR_Dir  = '/content/low_res_ndcld/SR/'\n",
        "print_error_statistics(_imgNameLow_Dir,_imgNameHigh_Dir,_imgNameSR_Dir,\"ndcld\",scale)\n",
        "print('ndcld')\n",
        "\n",
        "_imgNameLow_Dir = '/content/low_res_combined/'\n",
        "_imgNameHigh_Dir = '/content/high_res_combined/'\n",
        "_imgNameSR_Dir  = '/content/low_res_combined/SR/'\n",
        "print_error_statistics(_imgNameLow_Dir,_imgNameHigh_Dir,_imgNameSR_Dir,\"combined\",scale)\n",
        "print('combined')\n",
        "\n",
        "\n",
        "# casia V1  :\n",
        "NUM_EPOCHS = 40;\n",
        "_imgNameHigh_Dir = '/content/Dataset_casia_V1_HR/data/validation'\n",
        "scales = [2.0,3.0,4.0,5.0,6.0, 8.0,9.0,10.0,11.0,12.0,14.0,16.0]\n",
        "#1.5 excluded due to image size issue (even vs odd)\n",
        "for scale in scales:\n",
        "    # train \n",
        "    _imgNameLow_Dir = '/content/Dataset_casia_V1_LR_' + str(scale) + '/data/validation/SR_' + str(scale) # train lr images\n",
        "    _imgNameLow_Dir = '/content/Dataset_casia_V1_LR_' + str(scale) + '/data/validation/'\n",
        "    _imgNameSR_Dir = '/content/Dataset_casia_V1_LR_' + str(scale) + '/data/validation/SR_' + str(scale) # train sr images\n",
        "\n",
        "    print_error_statistics(_imgNameLow_Dir,_imgNameHigh_Dir,_imgNameSR_Dir,\"casia_V1\",scale)\n",
        "    print('scale =', scale ,' casia V1 print_error_statistics done')\n",
        "\n",
        "!cp -avr '/content/RESULT_SR_VS_ORIG_STATISTICS_casia_V1_20200119-191713.txt' '/content/drive/My Drive/Toar2/Thesis/Iris_recog/SR_Scaled_test_images/Casia_V1_test_sr/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niUjwgqiYg0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run statistis on all *Train* dataset and save log file\n",
        "_imgNameLow_Dir = '/content/Dataset_casia_V1_LR_8/data/train/'\n",
        "_imgNameHigh_Dir = '/content/Dataset_casia_V1_HR/data/train/'\n",
        "_imgNameSR_Dir  = '/content/Dataset_casia_V1_LR_8/data/train/SR'\n",
        "print_error_statistics(_imgNameLow_Dir,_imgNameHigh_Dir,_imgNameSR_Dir,\"casia_train\")\n",
        "print('casia _train')\n",
        "\n",
        "_imgNameLow_Dir = '/content/low_res_berc_train/'\n",
        "_imgNameHigh_Dir = '/content/high_res_berc_train/'\n",
        "_imgNameSR_Dir  = '/content/low_res_berc_train/SR/'\n",
        "print_error_statistics(_imgNameLow_Dir,_imgNameHigh_Dir,_imgNameSR_Dir,\"berc_train\")\n",
        "print('berc _train')\n",
        "\n",
        "_imgNameLow_Dir = '/content/low_res_ndcld_train/'\n",
        "_imgNameHigh_Dir = '/content/high_res_ndcld_train/'\n",
        "_imgNameSR_Dir  = '/content/low_res_ndcld_train/SR/'\n",
        "print_error_statistics(_imgNameLow_Dir,_imgNameHigh_Dir,_imgNameSR_Dir,\"ndcld_train\")\n",
        "print('ndcld _train')\n",
        "\n",
        "_imgNameLow_Dir = '/content/low_res_combined_train/'\n",
        "_imgNameHigh_Dir = '/content/high_res_combined_train/'\n",
        "_imgNameSR_Dir  = '/content/low_res_combined_train/SR/'\n",
        "print_error_statistics(_imgNameLow_Dir,_imgNameHigh_Dir,_imgNameSR_Dir,\"combined_train\")\n",
        "print('combined _train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc6g90XVWfvd",
        "colab_type": "text"
      },
      "source": [
        "**TODO:**\n",
        "change to 1 dimension only (greyscale)\n",
        "run on original dataset images small vs big - split dataset again *italicized text*"
      ]
    }
  ]
}